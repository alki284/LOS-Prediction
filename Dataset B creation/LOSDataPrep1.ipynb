{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "import statistics\n",
    "import sklearn\n",
    "%matplotlib inline\n",
    "from datetime import date\n",
    "from scipy import stats as stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ADMISSIONS = pd.read_csv(\"/Users/alex/ADMISSIONS.csv\")\n",
    "col_list = [\"SUBJECT_ID\", \"DOB\", \"GENDER\", \"EXPIRE_FLAG\"]\n",
    "df_PATIENTS = pd.read_csv(\"/Users/alex/PATIENTS.csv\", usecols=col_list)\n",
    "\n",
    "df_ADMISSIONS = pd.merge(df_ADMISSIONS, df_PATIENTS,on='SUBJECT_ID',how='outer',indicator=True)\n",
    "\n",
    "##Finds the difference between admission and discharge time and puts it into a list in hours\n",
    "\n",
    "date_mask = \"%Y-%m-%d %H:%M:%S\"\n",
    "df_ADMISSIONS['ADMITTIME'] = pd.to_datetime(df_ADMISSIONS['ADMITTIME'], format= date_mask)\n",
    "df_ADMISSIONS['DISCHTIME'] = pd.to_datetime(df_ADMISSIONS['DISCHTIME'], format= date_mask)\n",
    "df_ADMISSIONS['DOB'] = pd.to_datetime(df_ADMISSIONS['DOB'], format= date_mask)\n",
    "df_ADMISSIONS['LOS_hr'] = round(((df_ADMISSIONS['DISCHTIME'] - df_ADMISSIONS['ADMITTIME']).dt.total_seconds() / 3600))\n",
    "\n",
    "##Finds the differcne between DOB and admition time and works out the differnce in years\n",
    "age = []\n",
    "for i in range(0,58976):\n",
    "    datetime1 = pd.to_datetime(df_ADMISSIONS.DOB[i], format=date_mask)\n",
    "    datetime2 = pd.to_datetime(df_ADMISSIONS.ADMITTIME[i], format=date_mask)\n",
    "    days = datetime2 - datetime1\n",
    "    years_old = int(round(days.days/(366)))\n",
    "    age.append(years_old)\n",
    "df_ADMISSIONS['AGE'] = age\n",
    "\n",
    "##Replaces 300 year old patients with the 91 year old median value\n",
    "for i in range(0, 58976):\n",
    "    if df_ADMISSIONS.AGE[i] > 140:\n",
    "        df_ADMISSIONS[\"AGE\"].replace(df_ADMISSIONS.AGE[i], 91, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops Patient Records from ADMISSIONS based on exclusion criteria in paper.\n",
    "df_ADMISSIONS = df_ADMISSIONS.drop(df_ADMISSIONS[df_ADMISSIONS.EXPIRE_FLAG == 1].index)\n",
    "df_ADMISSIONS = df_ADMISSIONS.drop_duplicates(subset='SUBJECT_ID', keep='first')\n",
    "df_ADMISSIONS = df_ADMISSIONS.drop(df_ADMISSIONS[df_ADMISSIONS.HAS_CHARTEVENTS_DATA == 0].index)\n",
    "df_ADMISSIONS = df_ADMISSIONS.drop(df_ADMISSIONS[df_ADMISSIONS.AGE < 15].index)\n",
    "df_ADMISSIONS = df_ADMISSIONS.drop(df_ADMISSIONS[df_ADMISSIONS.LOS_hr < 0.1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Opens columns that appear in 'col_list' from CHARTEVENTS and OUTPUTEVENTS\n",
    "col_list = [\"HADM_ID\", \"ITEMID\", 'CHARTTIME', 'VALUE']\n",
    "df_OUTPUT = pd.read_csv(\"/Users/alex/OUTPUTEVENTS.csv\", usecols=col_list, chunksize = 1000000)\n",
    "df_EVENTS = pd.read_csv(\"/Users/alex/CHARTEVENTS.csv\", usecols=col_list, chunksize = 1000000)\n",
    "\n",
    "#Used to pair events with patient stays\n",
    "df_HADM = df_ADMISSIONS[['HADM_ID']]\n",
    "\n",
    "#Goes through chunks merging events that match HADM_ID of patients to df_HADM\n",
    "def preprocessing(chunk, df, lst):\n",
    "    df = pd.DataFrame(chunk)\n",
    "    common = df_HADM.merge(df,on=['HADM_ID','HADM_ID'])\n",
    "    df_HADM[(~df_HADM.HADM_ID.isin(common.HADM_ID))&(~df_HADM.HADM_ID.isin(common.HADM_ID))]\n",
    "    common = pd.DataFrame(common)\n",
    "    lst.append(common) \n",
    "\n",
    "\n",
    "output_lst = []\n",
    "for chunk in df_OUTPUT:\n",
    "    preprocessing(chunk, df_OUTPUT, output_lst)  \n",
    "output = pd.concat(output_lst)\n",
    "\n",
    "\n",
    "events_lst = []\n",
    "for chunk in df_EVENTS:\n",
    "    preprocessing(chunk, df_EVENTS, events_lst)  \n",
    "events = pd.concat(events_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function searches CHARTEVENTS for the ITEMIDs given in each list and forms them into a df named by the vital \n",
    "#it contains\n",
    "def sort_vitals(Vital_name,Vital, maxval, minval):\n",
    "    boolean_series = events.ITEMID.isin(Vital)\n",
    "    filtered_df = events[boolean_series].copy()\n",
    "    filtered_df['VALUE'] = pd.to_numeric(filtered_df['VALUE'], errors='coerce')\n",
    "    filtered_df.sort_values(by=['HADM_ID', 'CHARTTIME'])\n",
    "    filtered_df.fillna(method='ffill', inplace=True)\n",
    "    filtered_df['ITEM_NAME'] = Vital_name\n",
    "    filtered_df = filtered_df.drop(filtered_df[filtered_df.VALUE > maxval].index)\n",
    "    Vital = pd.DataFrame(filtered_df.drop(filtered_df[filtered_df.VALUE < minval].index))\n",
    "    return Vital\n",
    "\n",
    "\n",
    "systolicBP = [227243, 224167, 220179, 225309, 220050, 442, 455, 6701, 51]\n",
    "SystolicBP = sort_vitals('SystolicBP', systolicBP, 450, 0)\n",
    "\n",
    "Potassium =[227464, 829, 1535]\n",
    "Potassium = sort_vitals('Potassium', Potassium, 1000, 0)\n",
    "\n",
    "white_blood_cell = [220546, 861, 1127, 1542]\n",
    "White_Blood_Cell = sort_vitals('WBC', white_blood_cell, 1000, 0)\n",
    "\n",
    "sodium = [220645, 226534, 837, 1536]\n",
    "Sodium = sort_vitals('Sodium', sodium, 10000, 0)\n",
    "\n",
    "bicarbonate = [227443]\n",
    "Bicarbonate = sort_vitals('Bicarbonate', bicarbonate, 1000, 0)\n",
    "\n",
    "glasgow_coma = [198]\n",
    "Glasgow_Coma = sort_vitals('Glasgow_Coma', glasgow_coma, 1000, 0)\n",
    "\n",
    "birillium = [225690, 848, 1538, 225651, 803]\n",
    "Birillium = sort_vitals('Birillium', birillium, 10000, 0)\n",
    "\n",
    "Blood_Urea_Nitrogen = [225624, 781, 1162]\n",
    "BloodUreaNitrogen = sort_vitals('BloodUreaNitrogen', Blood_Urea_Nitrogen, 50000, 0)\n",
    "\n",
    "mech_vent = [223835, 3420, 3422, 190]\n",
    "Mech_Vent = sort_vitals('Mech_Vent', mech_vent, 50000, 0)\n",
    "\n",
    "Respiratory_Rate = [220210, 224690, 224689, 618, 614, 651, 615]\n",
    "Respiratory_Rate = sort_vitals('Respiratory_Rate', Respiratory_Rate, 650, 0)\n",
    "\n",
    "creatine = [220615, 791, 1525]\n",
    "Creatine = sort_vitals('Creatine', creatine, 1000, 0)\n",
    "\n",
    "diastolicBP = [224643, 220180, 220051,225310, 8441, 8555, 8368, 8440]\n",
    "diastolicBP = sort_vitals('diastolicBP', diastolicBP, 1000, 0)\n",
    "\n",
    "Oxygen_Saturation = [220277, 646, 834]\n",
    "Oxygen_Saturation = sort_vitals('Oxygen_Saturation', Oxygen_Saturation, 100, 0.1)\n",
    "\n",
    "hematocrit = [220545, 813]\n",
    "Hematocrit = sort_vitals('Hematocrit',hematocrit, 1000, 0)\n",
    "\n",
    "calcium = [225625, 786, 1522]\n",
    "Calcium = sort_vitals('Calcium', calcium, 50000, 0)\n",
    "\n",
    "magnesium = [220635, 821, 1532]\n",
    "Magnesium = sort_vitals('Magnesium', magnesium, 1000, 0)\n",
    "\n",
    "Albumin = [227456, 772, 1521]\n",
    "Albumin = sort_vitals('Albumin', Albumin, 50000, 0)\n",
    "\n",
    "pH = [220274, 860, 780, 223830, 1126]\n",
    "pH = sort_vitals('pH', pH, 10, 4)\n",
    "\n",
    "mean_BP = [220181, 224322, 225312, 220052, 224, 456, 6702, 52]\n",
    "Mean_BP = sort_vitals('Mean_BP', mean_BP, 500, 0)\n",
    "\n",
    "lactic_acid = [225668, 818, 1531]\n",
    "Lactic_Acid = sort_vitals('Lactic_Acid', lactic_acid, 200, 0)\n",
    "\n",
    "platelets = [227457, 828]\n",
    "Platelets = sort_vitals('Platelets', platelets, 10000, 0)\n",
    "\n",
    "red_blood = [833]\n",
    "Red_Blood = sort_vitals('Red_Blood', red_blood, 10000000, 0)\n",
    "\n",
    "white_blood_cell = [220546, 861, 1127, 1542]\n",
    "White_Blood_Cell = sort_vitals('White_blood_cell',white_blood_cell, 1000, 0)\n",
    "\n",
    "#These vitals required special manipulation so have their own code.\n",
    "\n",
    "weight = [224639, 226512, 226531, 763]\n",
    "boolean_series = events.ITEMID.isin(weight)\n",
    "filtered_df = events[boolean_series].copy()\n",
    "filtered_df['VALUE'] = pd.to_numeric(filtered_df['VALUE'], errors='coerce')\n",
    "filtered_df.sort_values(by=['HADM_ID', 'CHARTTIME'])\n",
    "filtered_df.fillna(method='ffill', inplace=True)\n",
    "filtered_df['VALUE'] = np.where(filtered_df['ITEMID'] == 226531, filtered_df['VALUE'] // 2.2, filtered_df['VALUE'])\n",
    "filtered_df = filtered_df.drop(filtered_df[filtered_df.VALUE > 1000].index)\n",
    "filtered_df['ITEM_NAME'] = 'Weight'\n",
    "Weight = filtered_df.drop(filtered_df[filtered_df.VALUE < 0.5].index)\n",
    "\n",
    "HeartRate = [220045, 211]\n",
    "boolean_series = events.ITEMID.isin(HeartRate)\n",
    "filtered_df = events[boolean_series].copy()\n",
    "filtered_df['VALUE'] = pd.to_numeric(filtered_df['VALUE'], errors='coerce')\n",
    "filtered_df.sort_values(by=['HADM_ID', 'CHARTTIME'])\n",
    "filtered_df.fillna(method='ffill', inplace=True)\n",
    "filtered_df.VALUE = pd.to_numeric(filtered_df.VALUE)\n",
    "filtered_df['ITEM_NAME'] = 'HeartRate'\n",
    "HeartRate = pd.DataFrame(filtered_df.drop(filtered_df[filtered_df.VALUE > 480].index))\n",
    "\n",
    "temperature = [223761, 223762, 676, 677, 678, 679]\n",
    "boolean_series = events.ITEMID.isin(temperature)\n",
    "filtered_df = events[boolean_series].copy()\n",
    "filtered_df['VALUE'] = pd.to_numeric(filtered_df['VALUE'], errors='coerce')\n",
    "filtered_df.sort_values(by=['HADM_ID', 'CHARTTIME'])\n",
    "filtered_df.fillna(method='ffill', inplace=True)\n",
    "filtered_df['VALUE'] = np.where(filtered_df['ITEMID'] == 223761, ((filtered_df['VALUE'] - 32) * 5/9), filtered_df['VALUE'])\n",
    "filtered_df = filtered_df.drop(filtered_df[filtered_df.VALUE > 47].index)\n",
    "filtered_df['ITEM_NAME'] = \"Temperature\"\n",
    "Temperature = pd.DataFrame(filtered_df.drop(filtered_df[filtered_df.VALUE < 10].index))\n",
    "\n",
    "urine = [40055, 43175, 40069, 40094, 40715, 40473, 40085, 40057, 40056, 40405, 40428, 40086,\n",
    "         40096, 40651, 226559, 226560, 226561, 226584, 226563, 226564, 226565, 226567, 226557, \n",
    "         226558, 227488, 227489]\n",
    "boolean_series = output.ITEMID.isin(urine)\n",
    "filtered_df = output[boolean_series].copy()\n",
    "filtered_df['VALUE'] = pd.to_numeric(filtered_df['VALUE'], errors='coerce')\n",
    "filtered_df.sort_values(by=['HADM_ID', 'CHARTTIME'])\n",
    "filtered_df.fillna(method='ffill', inplace=True)\n",
    "filtered_df['ITEM_NAME'] = \"Urine\"\n",
    "Urine = filtered_df.drop(filtered_df[filtered_df.VALUE > 50000].index)\n",
    "Urine = pd.DataFrame(filtered_df.drop(filtered_df[filtered_df.VALUE < 0].index))\n",
    "\n",
    "#Urine was only available from OUTPUT not EVENTS so this searches OUTPUT instead of EVENTS\n",
    "col_list = [\"ITEMID\", 'VALUEUOM']\n",
    "df_VALUEUOM = pd.read_csv(\"/Users/alex/OUTPUTEVENTS.csv\", usecols=col_list, nrows = 10000000)\n",
    "df_VALUEUOM = df_VALUEUOM.drop_duplicates(subset='ITEMID', keep='first')\n",
    "show = df_VALUEUOM.loc[df_VALUEUOM['ITEMID'].isin(urine)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [Mech_Vent, Urine, BloodUreaNitrogen, Birillium, Glasgow_Coma, Bicarbonate, Sodium, White_Blood_Cell,\n",
    "      Temperature, Potassium, SystolicBP, HeartRate, Red_Blood, Platelets, Lactic_Acid, Mean_BP, Weight, pH, \n",
    "     Albumin, Magnesium, Calcium, Hematocrit, Oxygen_Saturation, diastolicBP, Creatine, Respiratory_Rate]\n",
    "df = pd.concat(lst, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetches relevant columns from DIAGNOSES list\n",
    "diagnose_list = ['SUBJECT_ID', 'HADM_ID', 'ICD9_CODE']\n",
    "df_DIAGNOSES = pd.read_csv(\"/Users/alex/DIAGNOSES_ICD.csv\", usecols = diagnose_list)\n",
    "df_HADM = df_HADM.reset_index(drop=True)\n",
    "\n",
    "#Keeps diagnoses of patients who passed the elimination criteria \n",
    "common = df_HADM.merge(df_DIAGNOSES,on=['HADM_ID','HADM_ID'])\n",
    "df_HADM[(~df_HADM.HADM_ID.isin(common.HADM_ID))&(~df_HADM.HADM_ID.isin(common.HADM_ID))]\n",
    "df_DIAGNOSES = pd.DataFrame(common)\n",
    "\n",
    "#Puts ICD9 codes into a list\n",
    "ICD_9 = df_DIAGNOSES['ICD9_CODE'].tolist()\n",
    "E = []\n",
    "\n",
    "#Tranforms them into the first 3 characters if a number of beginning with V and first 4 if beginning with E\n",
    "for i in range(0, len(ICD_9)):\n",
    "    if ICD_9[i][0] == 'E':\n",
    "        E.append(ICD_9[i][0:4])\n",
    "    elif ICD_9[i][0] == 'V':\n",
    "        E.append(ICD_9[i][0:3])\n",
    "    else:\n",
    "        E.append(ICD_9[i][0:3])\n",
    "    \n",
    "\n",
    "ICD_9 = E\n",
    "\n",
    "#creates new dataframe to hold codes\n",
    "df_ICD9CODES = df_DIAGNOSES[['ICD9_CODE', 'HADM_ID']]\n",
    "df_ICD9CODES['ICD_CAT'] = ICD_9\n",
    "\n",
    "\n",
    "#Dicitionary with the 18 categories codes will be sorted into\n",
    "ICDDict = {\n",
    "1 : 'infectious and parasitic',\n",
    "2 : 'neoplasms',\n",
    "3 : 'endocrine, metabolic and immunity',\n",
    "4 : 'blood and blood-forming organs',\n",
    "5 : 'mental',\n",
    "6 : 'nervous',\n",
    "7 : 'circulatory',\n",
    "8 : 'respiratory',\n",
    "9 : 'digestive',\n",
    "10 : 'genitourinary',\n",
    "11 : 'pregnancy, childbirth, and puerperium',\n",
    "12 : 'skin and subcutaneous tissue',\n",
    "13 : 'musculoskeletal',\n",
    "14 : 'congenital',\n",
    "15 : 'perinatal period',\n",
    "16 : 'ill-defined',\n",
    "17 : 'injury and poisoning',\n",
    "18 : 'external causes of injury and supplemental classification'\n",
    "}\n",
    "\n",
    "NAME = []\n",
    "CAT = []\n",
    "#Goes through all ICD9 codes and appends the dictionary value for the ICD9 codes to list 'CAT'\n",
    "for i in range(0, 236104):\n",
    "    if ICD_9[i][0:1] == 'E' or ICD_9[i][0:1] == 'V':\n",
    "        CAT.append(18)\n",
    "    elif int(ICD_9[i]) <= 139:\n",
    "        CAT.append(1)\n",
    "    elif int(ICD_9[i]) > 139 and int(ICD_9[i]) <= 239:\n",
    "        CAT.append(2)\n",
    "    elif int(ICD_9[i]) > 239 and int(ICD_9[i]) <= 279:\n",
    "        CAT.append(3)\n",
    "    elif int(ICD_9[i]) > 279 and int(ICD_9[i]) <= 289:\n",
    "        CAT.append(4)\n",
    "    elif int(ICD_9[i]) > 289 and int(ICD_9[i]) <= 319:\n",
    "        CAT.append(5)\n",
    "    elif int(ICD_9[i]) > 319 and int(ICD_9[i]) <= 389:\n",
    "        CAT.append(6)\n",
    "    elif int(ICD_9[i]) > 389 and int(ICD_9[i]) <= 459:\n",
    "        CAT.append(7)\n",
    "    elif int(ICD_9[i]) > 460 and int(ICD_9[i]) <= 519:\n",
    "        CAT.append(8)\n",
    "    elif int(ICD_9[i]) > 519 and int(ICD_9[i]) <= 579:\n",
    "        CAT.append(9)\n",
    "    elif int(ICD_9[i]) > 579 and int(ICD_9[i]) <= 629:\n",
    "        CAT.append(10)\n",
    "    elif int(ICD_9[i]) > 629 and int(ICD_9[i]) <= 679:\n",
    "        CAT.append(11)\n",
    "    elif int(ICD_9[i]) > 679 and int(ICD_9[i]) <= 709:\n",
    "        CAT.append(12)\n",
    "    elif int(ICD_9[i]) > 709 and int(ICD_9[i]) <= 739:\n",
    "        CAT.append(13)\n",
    "    elif int(ICD_9[i]) > 739 and int(ICD_9[i]) <= 759:\n",
    "        CAT.append(14)\n",
    "    elif int(ICD_9[i]) > 759 and int(ICD_9[i]) <= 779:\n",
    "        CAT.append(15)\n",
    "    elif int(ICD_9[i]) > 779 and int(ICD_9[i]) <= 799:\n",
    "        CAT.append(16)\n",
    "    elif int(ICD_9[i]) > 799 and int(ICD_9[i]) <= 999:\n",
    "        CAT.append(17)\n",
    "\n",
    "#Creates new column for sorted codes and replaces the existing name with the name matched in the dictionary\n",
    "df_ICD9CODES['CATEGORY_ICD9'] = CAT\n",
    "df_ICD9CODES['ICD9_NAME'] = df_ICD9CODES['CATEGORY_ICD9'].replace(ICDDict)\n",
    "\n",
    "#Groups 'df_ICD9CODES' by HADM_ID and resets index\n",
    "ICD9HADMSort = df_ICD9CODES.groupby('HADM_ID')['ICD9_NAME'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates dummy variables for ICD9 Codes if you want to stakc, add .stack() after apply\n",
    "ICD9_Dummy = pd.get_dummies(ICD9HADMSort['ICD9_NAME'].apply(pd.Series).stack(), drop_first=False).sum(level=0)\n",
    "\n",
    "#Pairs them back with the inital data frame\n",
    "ICD9_Dummy = ICD9_Dummy.join(ICD9HADMSort['HADM_ID'], how=\"outer\")\n",
    "ICD9_Dummy = ICD9_Dummy.replace([2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These dictionaries reallocate different entries to the final groups which are to be entered.\n",
    "\n",
    "marriage_dictionary = {\n",
    "   \"SINGLE\" : \"SINGLE\",\n",
    "   \"MARRIED\" : \"MARRIED\",\n",
    "   \"DIVORCED\" : \"MARRIAGE ENDED\",\n",
    "   \"WIDOWED\" : \"MARRIAGE ENDED\",\n",
    "   \"SEPARATED\" : \"MARRIAGE ENDED\",\n",
    "   \"UNKNOWN (DEFAULT)\" : \"UNKNOWN\",\n",
    "   \"LIFE PARTNER\" : \"MARRIED\"\n",
    "                      }\n",
    "\n",
    "df_ADMISSIONS.MARITAL_STATUS.replace(marriage_dictionary, inplace=True)\n",
    "\n",
    "\n",
    "ethnicity_dictionary = {\n",
    "    'WHITE' : 'WHITE',\n",
    "    'UNKNOWN/NOT SPECIFIED' : 'UNKNOWN',\n",
    "    'MULTI RACE ETHNICITY' : 'UNKNOWN',\n",
    "    'BLACK/AFRICAN AMERICAN' : 'BLACK',\n",
    "    'HISPANIC OR LATINO' : 'HISPANIC',\n",
    "    'PATIENT DECLINED TO ANSWER' : 'UNKNOWN',\n",
    "    'ASIAN': 'ASIAN',\n",
    "    'OTHER' : 'OTHER',\n",
    "    'HISPANIC/LATINO - GUATEMALAN' : 'HISPANIC',\n",
    "    'ASIAN - VIETNAMESE' : 'ASIAN',\n",
    "    'AMERICAN INDIAN/ALASKA NATIVE' : 'OTHER',\n",
    "    'WHITE - RUSSIAN' : 'WHITE',\n",
    "    'HISPANIC/LATINO - PUERTO RICAN' : 'HISPANIC',\n",
    "    'ASIAN - ASIAN INDIAN' : 'ASIAN',\n",
    "    'HISPANIC/LATINO - SALVADORAN' : 'HISPANIC',\n",
    "    'HISPANIC/LATINO - DOMINICAN' : 'HISPANIC',\n",
    "    'UNABLE TO OBTAIN' : 'UNKNOWN',\n",
    "    'ASIAN - CHINESE' : 'ASIAN',\n",
    "    'BLACK/CAPE VERDEAN' : 'BLACK',\n",
    "    'WHITE - OTHER EUROPEAN' : 'WHITE',\n",
    "    'PORTUGUESE' : 'WHITE',\n",
    "    'BLACK/HAITIAN' : 'BLACK',\n",
    "    'SOUTH AMERICAN' : 'HISPANIC',\n",
    "    'CARIBBEAN ISLAND' : 'BLACK',\n",
    "    'WHITE - EASTERN EUROPEAN' : 'WHITE',\n",
    "    'ASIAN - FILIPINO' : 'ASIAN',\n",
    "    'ASIAN - CAMBODIAN' : 'ASIAN',\n",
    "    'HISPANIC/LATINO - CENTRAL AMERICAN (OTHER)' : 'HISPANIC',\n",
    "    'WHITE - BRAZILIAN' : 'WHITE',\n",
    "    'HISPANIC/LATINO - COLOMBIAN' : 'HISPANIC',\n",
    "    'ASIAN - JAPANESE' : 'ASIAN',\n",
    "    'NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER' : 'OTHER',\n",
    "    'BLACK/AFRICAN' : 'BLACK',\n",
    "    'ASIAN - THAI' : 'ASIAN',\n",
    "    'HISPANIC/LATINO - HONDURAN' : 'HISPANIC',\n",
    "    'MIDDLE EASTERN' : 'OTHER',\n",
    "    'ASIAN - OTHER' : 'ASIAN',\n",
    "    'HISPANIC/LATINO - CUBAN' : 'HISPANIC',\n",
    "    'HISPANIC/LATINO - MEXICAN' : 'HISPANIC',\n",
    "    'ASIAN - KOREAN' : 'ASIAN',\n",
    "    'AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNIZED TRIBE' : 'OTHER'\n",
    "                       }\n",
    "df_ADMISSIONS.ETHNICITY.replace(ethnicity_dictionary, inplace=True)\n",
    "\n",
    "\n",
    "religion_dictionary = {\n",
    "    'UNOBTAINABLE' : 'UNKNOWN',\n",
    "    'CATHOLIC' : 'CATHOLIC',\n",
    "    'PROTESTANT QUAKER' : 'PROTESTANT',\n",
    "    'NOT SPECIFIED' : 'UNKNOWN',\n",
    "    'JEWISH' : 'JEWISH',\n",
    "    'BUDDHIST' : 'NON-CHRISTIAN OTHER',\n",
    "    'OTHER' : 'UNKNOWN',\n",
    "    \"JEHOVAH'S WITNESS\" : 'CHRISTIAN OTHER',\n",
    "    'GREEK ORTHODOX' : 'CHRISTIAN OTHER',\n",
    "    'EPISCOPALIAN' : 'CHRISTIAN OTHER',\n",
    "    'HINDU' : 'NON-CHRISTIAN OTHER',\n",
    "    'CHRISTIAN SCIENTIST' : 'CHRISTIAN OTHER',\n",
    "    'HEBREW' : 'JEWISH',\n",
    "    'METHODIST' : 'CHRISTIAN OTHER',\n",
    "    'UNITARIAN-UNIVERSALIST' : 'CHRISTIAN OTHER',\n",
    "    'BAPTIST' : 'CHRISTIAN OTHER',\n",
    "    '7TH DAY ADVENTIST' : 'CHRISTIAN OTHER',\n",
    "    'MUSLIM' : 'NON-CHRISTIAN OTHER',\n",
    "    'ROMANIAN EAST. ORTH' : 'CHRISTIAN OTHER',\n",
    "    'LUTHERAN' : 'CHRISTIAN OTHER'\n",
    "}\n",
    "df_ADMISSIONS.RELIGION.replace(religion_dictionary, inplace=True)\n",
    "\n",
    "\n",
    "admission_location_dictionary = {\n",
    "    'EMERGENCY ROOM ADMIT' : 'EMERGENCY ROOM ADMIT',\n",
    "    'PHYS REFERRAL/NORMAL DELI' : 'PHYS REFERRAL/NORMAL DELI',\n",
    "    'TRANSFER FROM HOSP/EXTRAM' : 'TRANSFER FROM HOSP/EXTRAM',\n",
    "    'CLINIC REFERRAL/PREMATURE' : 'CLINIC REFERRAL/PREMATURE', \n",
    "    'TRANSFER FROM SKILLED NUR' : 'TRANSFER FROM SKILLED NUR',\n",
    "    'HMO REFERRAL/SICK' : 'HMO REFERRAL/SICK',\n",
    "    '** INFO NOT AVAILABLE **' : 'UNKNOWN',\n",
    "    'TRANSFER FROM OTHER HEALT' : 'TRANSFER FROM OTHER HEALT',\n",
    "    'TRSF WITHIN THIS FACILITY' : 'TRSF WITHIN THIS FACILITY'\n",
    "}\n",
    "df_ADMISSIONS.ADMISSION_LOCATION.replace(admission_location_dictionary, inplace=True)\n",
    "\n",
    "\n",
    "admission_type_dictionary = {\n",
    "    'EMERGENCY' : 'EMERGENCY',\n",
    "    'ELECTIVE' : 'ELECTIVE',\n",
    "    'NEWBORN' : 'NEWBORN',\n",
    "    'URGENT' : 'URGENT'\n",
    "}\n",
    "df_ADMISSIONS.ADMISSION_TYPE.replace(admission_type_dictionary, inplace=True)\n",
    "\n",
    "insurance_dictionary = {\n",
    "    'Private' : 'PRIVATE', \n",
    "    'Medicare' : 'GOVERNMENT', \n",
    "    'Medicaid' : 'GOVERNMENT', \n",
    "    'Self Pay' : 'SELF-PAY', \n",
    "    'Government' : 'GOVERNMENT'\n",
    "}\n",
    "df_ADMISSIONS.INSURANCE.replace(insurance_dictionary, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merges SAPSTime with ICD9_Dummy removing instances where HADM_ID does not match to anything\n",
    "common = df.merge(ICD9_Dummy,on=['HADM_ID','HADM_ID'])\n",
    "df[(~df.HADM_ID.isin(common.HADM_ID))&(~df.HADM_ID.isin(common.HADM_ID))]\n",
    "df = pd.DataFrame(common)\n",
    "\n",
    "df_Demo = df_ADMISSIONS[['AGE', 'HADM_ID', 'LOS_hr', 'ADMITTIME', 'DISCHTIME', 'ADMISSION_TYPE',\n",
    "                        'ADMISSION_LOCATION', 'INSURANCE', 'RELIGION', 'MARITAL_STATUS', 'ETHNICITY']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove hot one encodes categorical variables\n",
    "admission_type = pd.get_dummies(df_Demo['ADMISSION_TYPE'], drop_first=False).sum(level = 0)\n",
    "admission_location = pd.get_dummies(df_Demo['ADMISSION_LOCATION'], drop_first=False).sum(level = 0)\n",
    "insurance = pd.get_dummies(df_Demo['INSURANCE'], drop_first=False).sum(level = 0)\n",
    "religion = pd.get_dummies(df_Demo['RELIGION'], drop_first=False).sum(level = 0)\n",
    "martial_status = pd.get_dummies(df_Demo['MARITAL_STATUS'], drop_first=False).sum(level = 0)\n",
    "ethnicity = pd.get_dummies(df_Demo['ETHNICITY'], drop_first=False).sum(level = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates an array joining dummies together\n",
    "df_dummy = []\n",
    "df_dummy = admission_type.join(df_Demo['HADM_ID'], how = \"outer\")\n",
    "df_dummy = admission_location.join(df_dummy, how = \"outer\")\n",
    "df_dummy = insurance.join(df_dummy, how = \"outer\")\n",
    "df_dummy = religion.join(df_dummy, how = \"outer\", lsuffix='religion')\n",
    "df_dummy = martial_status.join(df_dummy, how = \"outer\", lsuffix='marriage')\n",
    "df_dummy = ethnicity.join(df_dummy, how = \"outer\", lsuffix='ethnicity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "common = df_Demo.merge(df_dummy,on=['HADM_ID','HADM_ID'])\n",
    "df_Demo[(~df_Demo.HADM_ID.isin(common.HADM_ID))&(~df_Demo.HADM_ID.isin(common.HADM_ID))]\n",
    "df_Demo = pd.DataFrame(common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drops names of categories leaving only hot one encodings\n",
    "df_Demo = df_Demo.drop(['ADMISSION_TYPE'], axis = 1)\n",
    "df_Demo = df_Demo.drop(['ADMISSION_LOCATION'], axis = 1)\n",
    "df_Demo = df_Demo.drop(['INSURANCE'], axis = 1)\n",
    "df_Demo = df_Demo.drop(['RELIGION'], axis = 1)\n",
    "df_Demo = df_Demo.drop(['MARITAL_STATUS'], axis = 1)\n",
    "df_Demo = df_Demo.drop(['ETHNICITY'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates bins for ages and hot one encodes them.\n",
    "pd.cut(df_Demo.AGE, 10)\n",
    "bins = [14, 40, 59, 69, 74, 79, 99]\n",
    "labels =['1','2','3','4', '5', '6']\n",
    "df_Demo['AGE BIN'] = pd.cut(df_Demo['AGE'], bins,labels=labels)\n",
    "df_Demo = df_Demo.drop(['AGE'], axis = 1)\n",
    "\n",
    "age_item = pd.get_dummies(df_Demo['AGE BIN'], prefix='Age Bin', drop_first=True)\n",
    "df_Demo = df_Demo.join(age_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "common = df.merge(df_Demo,on=['HADM_ID','HADM_ID'])\n",
    "df[(~df.HADM_ID.isin(common.HADM_ID))&(~df.HADM_ID.isin(common.HADM_ID))]\n",
    "df = pd.DataFrame(common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Works out hours left, hours in and shifts left and rounds timestamps to nearest hour\n",
    "df['ADMITTIME'] = pd.to_datetime(df['ADMITTIME'], format= date_mask)\n",
    "df['CHARTTIME'] = pd.to_datetime(df['CHARTTIME'], format= date_mask)\n",
    "df['DISCHTIME'] = pd.to_datetime(df['DISCHTIME'], format= date_mask)\n",
    "df['HOURS_IN'] = round(((df['CHARTTIME'] - df['ADMITTIME']).dt.total_seconds() / 3600))\n",
    "df['HOURS_LEFT'] = round(((df['DISCHTIME'] - df['CHARTTIME']).dt.total_seconds() / 3600))\n",
    "df['SHIFTS_LEFT'] = round((df['HOURS_LEFT'] / 8))\n",
    "df.sort_values(by='CHARTTIME')\n",
    "df['CHARTTIME'] = pd.to_datetime(df['CHARTTIME']) \n",
    "df['CHARTTIME'] = df['CHARTTIME'].dt.round('H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorts dataframe by time and drops duplicates keeping the first \n",
    "df_time = df.sort_values(by=['CHARTTIME'], ascending = True)\n",
    "df_time = df_time.drop_duplicates(subset=['CHARTTIME', 'HADM_ID', 'ITEM_NAME'], keep='first')\n",
    "df_time = df_time.drop(df_time[df_time.LOS_hr < 4].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saves df to file '50varraw'\n",
    "df_time.to_csv('50varraw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
