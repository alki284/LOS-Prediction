{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "import statistics\n",
    "import sklearn\n",
    "%matplotlib inline\n",
    "from datetime import date\n",
    "from scipy import stats as stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from datetime import datetime, timedelta\n",
    "from tensorflow import keras as keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer\n",
    "from numpy import asarray\n",
    "from numpy import savetxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(\"/Users/alex/df_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'HeartRate', 'SystolicBP', 'Potassium', 'Temperature',\n",
       "       'White_Blood_Cell', 'Sodium', 'Bicarbonate', 'Glasgow_Coma',\n",
       "       'Birillium', 'BloodUreaNitrogen', 'Urine', 'Mech_Vent', 'HeartRateMask',\n",
       "       'SystolicBPMask', 'PotassiumMask', 'TemperatureMask',\n",
       "       'White_Blood_CellMask', 'SodiumMask', 'BicarbonateMask',\n",
       "       'Glasgow_ComaMask', 'BirilliumMask', 'BloodUreaNitrogenMask',\n",
       "       'UrineMask', 'Mech_VentMask', 'HADM_ID',\n",
       "       'blood and blood-forming organs', 'circulatory', 'congenital',\n",
       "       'digestive', 'endocrine, metabolic and immunity',\n",
       "       'external causes of injury and supplemental classification',\n",
       "       'genitourinary', 'ill-defined', 'infectious and parasitic',\n",
       "       'injury and poisoning', 'mental', 'musculoskeletal', 'neoplasms',\n",
       "       'nervous', 'perinatal period', 'pregnancy, childbirth, and puerperium',\n",
       "       'respiratory', 'skin and subcutaneous tissue', 'EMERGENCY', 'URGENT',\n",
       "       'AGE BIN', 'Age Bin_2', 'Age Bin_3', 'Age Bin_4', 'Age Bin_5',\n",
       "       'Age Bin_6', 'Age Bin_7', 'Age Bin_8', 'Age Bin_9', 'Age Bin_10',\n",
       "       'Age Bin_11', 'Age Bin_12', 'Age Bin_13', 'Age Bin_14', 'Age Bin_15',\n",
       "       'Age Bin_16', 'HOURS_IN', 'HOURS_LEFT', 'LOS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a table of each vital with its mask\n",
    "HR = df_all[['HADM_ID','HeartRate', 'HOURS_IN', 'HOURS_LEFT', 'LOS', 'HeartRateMask']]\n",
    "BP = df_all[['HADM_ID','SystolicBP', 'HOURS_IN', 'HOURS_LEFT', 'LOS', 'SystolicBPMask']]\n",
    "Pot = df_all[['HADM_ID','Potassium', 'HOURS_IN', 'HOURS_LEFT', 'LOS', 'PotassiumMask']]\n",
    "Temp = df_all[['HADM_ID','Temperature', 'HOURS_IN', 'HOURS_LEFT', 'LOS', 'TemperatureMask']]\n",
    "WBC = df_all[['HADM_ID','White_Blood_Cell', 'HOURS_IN', 'HOURS_LEFT', 'LOS', 'White_Blood_CellMask']]\n",
    "Na = df_all[['HADM_ID','Sodium', 'HOURS_IN', 'HOURS_LEFT', 'LOS', 'SodiumMask']]\n",
    "Bi = df_all[['HADM_ID','Bicarbonate', 'HOURS_IN', 'HOURS_LEFT', 'LOS', 'BicarbonateMask']]\n",
    "Glas = df_all[['HADM_ID','Glasgow_Coma', 'HOURS_IN', 'HOURS_LEFT', 'LOS', 'Glasgow_ComaMask']]\n",
    "Biril = df_all[['HADM_ID','Birillium', 'HOURS_IN', 'HOURS_LEFT', 'LOS', 'BirilliumMask']]\n",
    "BUN = df_all[['HADM_ID','BloodUreaNitrogen', 'HOURS_IN', 'HOURS_LEFT', 'LOS', 'BloodUreaNitrogenMask']]\n",
    "Urine = df_all[['HADM_ID','Urine', 'HOURS_IN', 'HOURS_LEFT', 'LOS', 'UrineMask']]\n",
    "Mech_Vent = df_all[['HADM_ID','Mech_Vent', 'HOURS_IN', 'HOURS_LEFT', 'LOS', 'Mech_VentMask']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list to make columns for timeframe\n",
    "names = []\n",
    "for i in range(0, 336):\n",
    "    j = str(i)\n",
    "    names.append(j)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Makes y for prediction\n",
    "def makeanswer(data):\n",
    "    length = 336\n",
    "    hadmlist = data['HADM_ID'].unique()\n",
    "    timeline = pd.DataFrame({'HADM_ID': hadmlist},columns = names)\n",
    "    timeline['HADM_ID'] = hadmlist\n",
    "    y = []\n",
    "    for i in range(0, len(hadmlist)):\n",
    "        df = data[data['HADM_ID'] == hadmlist[i]]\n",
    "        lst = []\n",
    "        counter = 0\n",
    "        for j in range(1, (len(df)-1)):\n",
    "            pos = int(df.iloc[j, 2])\n",
    "            left = int(df.iloc[j, 3])\n",
    "            if pos > 335:\n",
    "                pass\n",
    "            else:\n",
    "                lst.append(left)\n",
    "        y.append(lst)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = makeanswer(HR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22404"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(answers)\n",
    "y.to_csv(r'/Users/alex/SAPSy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeset(data, value):\n",
    "    length = 336\n",
    "    hadmlist = data['HADM_ID'].unique()\n",
    "    timeline = pd.DataFrame({'HADM_ID': hadmlist},columns = names)\n",
    "    mask = pd.DataFrame({'HADM_ID': hadmlist},columns = names)\n",
    "    timeline['HADM_ID'] = hadmlist\n",
    "    mask['HADM_ID'] = hadmlist\n",
    "    cols = []\n",
    "    c = []\n",
    "    y = []\n",
    "    percent = 0\n",
    "    for i in range(0, len(hadmlist)-1):\n",
    "        if (i % 224 ) == 0:\n",
    "            percent += 1\n",
    "            print(str(percent) + '% done.') \n",
    "        df = data[data['HADM_ID'] == hadmlist[i]]\n",
    "        lst = []\n",
    "        counter = 0\n",
    "        for j in range(1, (len(df)-1)):\n",
    "            timein = int(df.iloc[j, 4])\n",
    "            value = int(df.iloc[j, 1])\n",
    "            pos = int(df.iloc[j, 2])\n",
    "            left = int(df.iloc[j, 3])\n",
    "            if pos > 335:\n",
    "                pass\n",
    "            else:\n",
    "                timeline.iloc[i, pos] = value\n",
    "                mask.iloc[i, pos] = 1\n",
    "                lst.append(left)\n",
    "            if timein < length:\n",
    "                timeline.iloc[i, timein] = -1\n",
    "\n",
    "        y.append(lst)\n",
    "        \n",
    "    timeline = timeline.iloc[:, 1:]\n",
    "    mask = mask.iloc[:, 1:]\n",
    "    mask = mask.fillna(0)\n",
    "    timeline = timeline.ffill(axis = 1)\n",
    "    timeline = timeline.fillna(value=value)\n",
    "    \n",
    "    return timeline, mask, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makechannel(data, name):\n",
    "    channel = pd.DataFrame()\n",
    "    for i in range(0, 336):\n",
    "        j = str(i)\n",
    "        mname = ('m' + name + j)\n",
    "        tname = ('t'+ name + j)\n",
    "        channel[tname] = data[0].iloc[:, i]\n",
    "        channel[mname] = data[1].iloc[:,i]\n",
    "    return channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo = pd.read_csv(\"/Users/alex/df_sapsdemo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hadmlist = HR['HADM_ID'].unique()\n",
    "hadmlist = pd.DataFrame(hadmlist)\n",
    "hadmlist['HADM_ID'] = hadmlist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demodata = pd.merge(hadmlist, df_demo, on='HADM_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demodata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demodata = demodata.drop_duplicates(subset = ['HADM_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demodata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = set(hadmlist['HADM_ID']).symmetric_difference(set(demodata['HADM_ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmissing = pd.DataFrame({'HADM_ID': [107486, 130888, 136883, 141974, 189968], \n",
    "                          'EMERGENCY': [0,0,0,0,0], \n",
    "                          'URGENT': [0,0,0,0,0], \n",
    "                          'Age Bin_1': [0,0,0,0,0],\n",
    "                          'Age Bin_2': [0,0,0,0,0], \n",
    "                          'Age Bin_3': [0,0,0,0,0], \n",
    "                          'Age Bin_4': [0,0,0,0,0], \n",
    "                          'Age Bin_5': [0,0,0,0,0], \n",
    "                          'Age Bin_6': [0,0,0,0,0],\n",
    "                          'infectious and parasitic': [0,0,0,0,0], \n",
    "                          'neoplasms': [0,0,0,0,0],\n",
    "                          'blood and blood-forming organs': [0,0,0,0,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demodata = demodata.append(dfmissing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demodata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demodata = demodata[[ 'HADM_ID','EMERGENCY','URGENT','Age Bin_1', 'Age Bin_2','Age Bin_3','Age Bin_4','Age Bin_5',\n",
    "                        'Age Bin_6','infectious and parasitic','neoplasms', 'blood and blood-forming organs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demodata = pd.merge(hadmlist, demodata, on='HADM_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demodata.to_csv(r'/Users/alex/df_sapsdemo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HR = makeset(HR, 86)\n",
    "HRSave = makechannel(HR, 'HR')\n",
    "HRSave.to_csv(r'/Users/alex/HR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BP = makeset(BP, 120)\n",
    "BPSave = makechannel(BP, 'BP')\n",
    "BPSave.to_csv(r'/Users/alex/BP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pot = makeset(Pot, 4.3)\n",
    "PotSave = makechannel(Pot, 'Pot')\n",
    "PotSave.to_csv(r'/Users/alex/Pot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Temp = makeset(Temp, 37.8)\n",
    "TempSave = makechannel(Temp, 'Temp')\n",
    "TempSave.to_csv(r'/Users/alex/Temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WBC = makeset(WBC, 9)\n",
    "#WBCSave = makechannel(WBC, 'WBC')\n",
    "#WBCSave.to_csv(r'/Users/alex/WBC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Na = makeset(Na, 140)\n",
    "#NaSave = makechannel(Na, 'Na')\n",
    "#NaSave.to_csv(r'/Users/alex/Na.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bi = makeset(Bi, 26)\n",
    "#BiSave = makechannel(Bi, 'Bi')\n",
    "#BiSave.to_csv(r'/Users/alex/Bi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Glas = makeset(Glas, 3)\n",
    "#GlasSave = makechannel(Glas, 'Glas')\n",
    "#GlasSave.to_csv(r'/Users/alex/Glas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mech_Vent = makeset(Mech_Vent, 0)\n",
    "MechSave = makechannel(Mech_Vent, 'Mech_Vent')\n",
    "MechSave.to_csv(r'/Users/alex/Mech_Vent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Biril = makeset(Biril, 0.2)\n",
    "BirilSave = makechannel(Biril, 'Biril')\n",
    "BirilSave.to_csv(r'/Users/alex/Biril.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Urine = makeset(Urine, 150)\n",
    "UrineSave = makechannel(Urine, 'Urine')\n",
    "UrineSave.to_csv(r'/Users/alex/Urine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUN = makeset(BUN, 4.7)\n",
    "BUNSave = makechannel(BUN, 'BUN')\n",
    "BUNSave.to_csv(r'/Users/alex/BUN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makey(data):\n",
    "    y = data[2]\n",
    "    return y\n",
    "\n",
    "y = makey(HR)\n",
    "y = pd.DataFrame(y)\n",
    "y.to_csv(r'/Users/alex/SAPSy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [HR, BP, Pot, Temp, WBC, Na, Bi, Glas, Mech_Vent, Biril, Urine, BUN]\n",
    "lstdata = ['HR', 'BP', 'Pot', 'Temp', 'WBC', 'Na', 'Bi', 'Glas', 'Mech_Vent', 'Biril', 'Urine', 'BUN']\n",
    "demo = demodata\n",
    "lstdemo = ['Age1' , 'Age2', 'Age3', 'Age4', 'Age5', 'AIDS', 'Hema', 'Cancer', admissions here]\n",
    "\n",
    "def makefinal(lst, lstdata, demo, lstdemo):\n",
    "    binary = pd.DataFrame()\n",
    "    for i in range(0, 336):\n",
    "        j = str(i)\n",
    "        for k in range(0, len(lstdata)):\n",
    "            mname = ('m' + str(lstdata[k]) + j)\n",
    "            tname = ('t'+ lstdata[k] + j)\n",
    "            \n",
    "            binary[tname] = lst[k][0].iloc[:, i]\n",
    "            binary[mname] = lst[k][1].iloc[:, i]\n",
    "        for l in range(0, len(lstdemo)):\n",
    "            dname = (lstdemo[l] + j)\n",
    "            binary[dname] = demo.iloc[:, l]\n",
    "        \n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makechannel(data, name):\n",
    "    channel = pd.DataFrame()\n",
    "    for i in range(0, 336):\n",
    "        j = str(i)\n",
    "        mname = ('m' + name + j)\n",
    "        tname = ('t'+ name + j)\n",
    "        channel[tname] = data[0].iloc[:, i]\n",
    "        channel[mname] = data[1].iloc[:,i]\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = makefinal(lst, lstdata)\n",
    "binary = np.asarray(binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(binary, test_size=0.15, shuffle = False)\n",
    "\n",
    "print(train.shape[0])\n",
    "print(test.shape[0])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "trnx = scaler.fit_transform(train)\n",
    "tstx = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "y = pad_sequences(y, padding= 'post' )\n",
    "trny = y[:850]\n",
    "tsty = y[850:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trny.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trnx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save numpy array as csv file\n",
    "from numpy import asarray\n",
    "from numpy import savetxt\n",
    "# save to csv file\n",
    "savetxt('binSAPSIItrnx.csv', trnx, delimiter=',')\n",
    "savetxt('binSAPSIItrny.csv', trny, delimiter=',')\n",
    "savetxt('binSAPSIItstx.csv', tstx, delimiter=',')\n",
    "savetxt('binSAPSIItsty.csv', tsty, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trnx = trnx.reshape((trnx.shape[0], 336, 24))\n",
    "tstx = tstx.reshape((tstx.shape[0], 336, 24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trnx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import tensorflow\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from tensorflow import keras as keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer\n",
    "from numpy import loadtxt\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Concatenate, Dense, LSTM, Input, concatenate, Dropout, TimeDistributed\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "tensorflow.keras.backend.set_floatx('float64')\n",
    "\n",
    "cells = 128\n",
    "\n",
    "inptrnx = Input(shape=(trnx.shape[1], trnx.shape[2]))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(cells, return_sequences = True, input_shape=(trnx.shape[1], trnx.shape[2])))\n",
    "model.add(LSTM(cells, return_sequences = True))\n",
    "model.add(TimeDistributed(Dense(1, activation = 'relu')))\n",
    "model.compile(optimizer= 'adam' , loss= 'mean_squared_error' , \n",
    "                metrics=['mean_absolute_percentage_error'])\n",
    "\n",
    "#MAD, MAPE, MSE, MSLE, R2, Kappa \n",
    "history = model.fit(trnx, trny, \n",
    "                epochs=8, batch_size = 128, validation_split=0.1, verbose=2)\n",
    "\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(tstx, tsty, batch_size = 128)\n",
    "print(\"MSE, ACC, MAE:\", results)\n",
    "\n",
    "\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
